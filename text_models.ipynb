{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5ae78b",
   "metadata": {},
   "source": [
    "## ChatGPT Sample Notebook\n",
    "Simple notebook to make text completion API calls to ChatGPT using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI               # text completion model\n",
    "from langchain.chat_models import ChatOpenAI    # chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd6c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2857593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if reading from file\n",
    "# f = open(oaik.txt)\n",
    "# api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982ecbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4151/1880544328.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(openai_api_key = api_key)\n",
      "/tmp/ipykernel_4151/1880544328.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm('Here is a fun fact about Pluto'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Pluto was originally discovered by American astronomer Clyde Tombaugh in 1930. However, it was later reclassified as a dwarf planet in 2006 by the International Astronomical Union.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key = api_key)\n",
    "print(llm('Here is a fun fact about Pluto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e18c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.generate(['Here is a fact about Pluto', 'Here is a fact about Mars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeda3783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'BaseMessage': {'additionalProperties': True,\n",
       "   'description': 'Base abstract message class.\\n\\nMessages are the inputs and outputs of ChatModels.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessage',\n",
       "   'type': 'object'},\n",
       "  'BaseMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk, which can be concatenated with other Message chunks.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'},\n",
       "         {'additionalProperties': True, 'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'additionalProperties': True,\n",
       "     'title': 'Additional Kwargs',\n",
       "     'type': 'object'},\n",
       "    'response_metadata': {'additionalProperties': True,\n",
       "     'title': 'Response Metadata',\n",
       "     'type': 'object'},\n",
       "    'type': {'title': 'Type', 'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'type'],\n",
       "   'title': 'BaseMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatGeneration': {'description': 'A single chat generation output.\\n\\nA subclass of Generation that represents the response from a chat model\\nthat generates chat messages.\\n\\nThe `message` attribute is a structured representation of the chat message.\\nMost of the time, the message will be of type `AIMessage`.\\n\\nUsers working with chat models will usually access information via either\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks).',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGeneration',\n",
       "     'default': 'ChatGeneration',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessage'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGeneration',\n",
       "   'type': 'object'},\n",
       "  'ChatGenerationChunk': {'description': 'ChatGeneration chunk.\\n\\nChatGeneration chunks can be concatenated with other ChatGeneration chunks.',\n",
       "   'properties': {'text': {'default': '', 'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'ChatGenerationChunk',\n",
       "     'default': 'ChatGenerationChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'message': {'$ref': '#/$defs/BaseMessageChunk'}},\n",
       "   'required': ['message'],\n",
       "   'title': 'ChatGenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'Generation': {'description': 'A single text generation output.\\n\\nGeneration represents the response from an \"old-fashioned\" LLM that\\ngenerates regular text (not chat messages).\\n\\nThis model is used internally by chat model and will eventually\\nbe mapped to a more general `LLMResult` object, and then projected into\\nan `AIMessage` object.\\n\\nLangChain users working with chat models will usually access information via\\n`AIMessage` (returned from runnable interfaces) or `LLMResult` (available\\nvia callbacks). Please refer the `AIMessage` and `LLMResult` schema documentation\\nfor more information.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'Generation',\n",
       "   'type': 'object'},\n",
       "  'GenerationChunk': {'description': 'Generation chunk, which can be concatenated with other Generation chunks.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'anyOf': [{'additionalProperties': True,\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Generation Info'},\n",
       "    'type': {'const': 'Generation',\n",
       "     'default': 'Generation',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'GenerationChunk',\n",
       "   'type': 'object'},\n",
       "  'RunInfo': {'description': 'Class that contains metadata for a single execution of a Chain or model.\\n\\nDefined for backwards compatibility with older versions of langchain_core.\\n\\nThis model will likely be deprecated in the future.\\n\\nUsers can acquire the run_id information from callbacks or via run_id\\ninformation present in the astream_event API (depending on the use case).',\n",
       "   'properties': {'run_id': {'format': 'uuid',\n",
       "     'title': 'Run Id',\n",
       "     'type': 'string'}},\n",
       "   'required': ['run_id'],\n",
       "   'title': 'RunInfo',\n",
       "   'type': 'object'}},\n",
       " 'description': 'A container for results of an LLM call.\\n\\nBoth chat models and LLMs generate an LLMResult object. This object contains\\nthe generated outputs and any additional information that the model provider\\nwants to return.',\n",
       " 'properties': {'generations': {'items': {'items': {'anyOf': [{'$ref': '#/$defs/Generation'},\n",
       "      {'$ref': '#/$defs/ChatGeneration'},\n",
       "      {'$ref': '#/$defs/GenerationChunk'},\n",
       "      {'$ref': '#/$defs/ChatGenerationChunk'}]},\n",
       "    'type': 'array'},\n",
       "   'title': 'Generations',\n",
       "   'type': 'array'},\n",
       "  'llm_output': {'anyOf': [{'additionalProperties': True, 'type': 'object'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Llm Output'},\n",
       "  'run': {'anyOf': [{'items': {'$ref': '#/$defs/RunInfo'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Run'},\n",
       "  'type': {'const': 'LLMResult',\n",
       "   'default': 'LLMResult',\n",
       "   'title': 'Type',\n",
       "   'type': 'string'}},\n",
       " 'required': ['generations'],\n",
       " 'title': 'LLMResult',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2286c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 131,\n",
       "  'total_tokens': 143,\n",
       "  'prompt_tokens': 12},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0323f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Generation(text=':\\nPluto was discovered in 1930 by American astronomer Clyde W. Tombaugh at the Lowell Observatory in Flagstaff, Arizona.', generation_info={'finish_reason': 'stop', 'logprobs': None})],\n",
       " [Generation(text=': Mars is the fourth planet from the sun in our solar system. It is known as the \"Red Planet\" due to its reddish appearance caused by iron oxide (rust) on its surface. Mars has a thin atmosphere that is mostly made up of carbon dioxide. It is also home to the largest volcano in the solar system, Olympus Mons, and the deepest canyon, Valles Marineris. Scientists believe that Mars may have once had liquid water on its surface and could potentially support life. ', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e3d48a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Generation(text=':\\nPluto was discovered in 1930 by American astronomer Clyde W. Tombaugh at the Lowell Observatory in Flagstaff, Arizona.', generation_info={'finish_reason': 'stop', 'logprobs': None})],\n",
       " [Generation(text=': Mars is the fourth planet from the sun in our solar system. It is known as the \"Red Planet\" due to its reddish appearance caused by iron oxide (rust) on its surface. Mars has a thin atmosphere that is mostly made up of carbon dioxide. It is also home to the largest volcano in the solar system, Olympus Mons, and the deepest canyon, Valles Marineris. Scientists believe that Mars may have once had liquid water on its surface and could potentially support life. ', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375ef1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=': Mars is the fourth planet from the sun in our solar system. It is known as the \"Red Planet\" due to its reddish appearance caused by iron oxide (rust) on its surface. Mars has a thin atmosphere that is mostly made up of carbon dioxide. It is also home to the largest volcano in the solar system, Olympus Mons, and the deepest canyon, Valles Marineris. Scientists believe that Mars may have once had liquid water on its surface and could potentially support life. ' generation_info={'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(result.generations[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
